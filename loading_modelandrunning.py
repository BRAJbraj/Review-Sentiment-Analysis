# -*- coding: utf-8 -*-
"""loading_modelandrunning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xOjSrr0MbR_6rMH-MK_i6jXzqHgRrH4X
"""

# import time
# start=time.time()

import tensorflow
from tensorflow import keras
from tensorflow.keras.preprocessing.text import text_to_word_sequence
from tensorflow.keras.preprocessing.sequence import pad_sequences
import os
import sys

os.chdir(r'C:\Users\DELL\Downloads')

model = keras.models.load_model('imdb_model (5).keras')

# for training the model we used keras built-in imdb dataset,so we are using the same dataset for preparing the input for the model.
from keras.datasets import imdb

vocab=imdb.get_word_index() # this gives the vocabulary of the imdb dataset

#imdb dataset has 88584 words in its vocab but we used the most frequent 10000 words while training as well as preparing the input.
filtered_vocab={}
for i,j in vocab.items():
  if j<25000:
    filtered_vocab[i]=j

# this code converts the text given to the model into integers before passing to the model.
def encode_text(text):
    # Tokenize the text
    words_list = text_to_word_sequence(text)
    #print(words_list)
    token=[]
    for words in words_list:
      if words in filtered_vocab:
        token.append(filtered_vocab[words])
      else:
        token.append(2)
    return (pad_sequences([token],maxlen=300))

# this code calls encode_text function and model.
def predict_review(review):
  result=model.predict(encode_text(review))
  return result

if __name__=="__main__":
  review_text=sys.stdin.read()
  res= predict_review(review_text)
  if res<0.5:
    print("The review is negative")
  else:
    print("The review is positive")